{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a0c5994",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.009085,
     "end_time": "2025-06-20T10:20:58.024167",
     "exception": false,
     "start_time": "2025-06-20T10:20:58.015082",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 주어진 데이터(basic2.csv)에서 주 단위 Sales의 합계를 구하고, 가장 큰 값을 가진 주와 작은 값을 가진 주의 차이를 구하시오(절대값)\n",
    "- 데이터셋 : basic2.csv\n",
    "- 오른쪽 상단 copy&edit 클릭 -> 예상문제 풀이 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fa2982f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T10:20:58.047840Z",
     "iopub.status.busy": "2025-06-20T10:20:58.047275Z",
     "iopub.status.idle": "2025-06-20T10:20:58.050246Z",
     "shell.execute_reply": "2025-06-20T10:20:58.050663Z",
     "shell.execute_reply.started": "2025-06-20T10:20:00.531088Z"
    },
    "papermill": {
     "duration": 0.018763,
     "end_time": "2025-06-20T10:20:58.050919",
     "exception": false,
     "start_time": "2025-06-20T10:20:58.032156",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9698cfe9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T10:20:58.070406Z",
     "iopub.status.busy": "2025-06-20T10:20:58.069637Z",
     "iopub.status.idle": "2025-06-20T10:20:58.093990Z",
     "shell.execute_reply": "2025-06-20T10:20:58.093548Z",
     "shell.execute_reply.started": "2025-06-20T10:20:00.537498Z"
    },
    "papermill": {
     "duration": 0.035882,
     "end_time": "2025-06-20T10:20:58.094114",
     "exception": false,
     "start_time": "2025-06-20T10:20:58.058232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../input/bigdatacertificationkr/basic2.csv\", parse_dates=['Date'], index_col=0)\n",
    "\n",
    "# 아래 코드를 한줄로 표현함\n",
    "# df = pd.read_csv(\"../input/bigdatacertificationkr/basic2.csv\")\n",
    "# df['Date'] = pd.to_datetime(df['Date'])\n",
    "# df = df.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2bef17b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T10:20:58.118530Z",
     "iopub.status.busy": "2025-06-20T10:20:58.117490Z",
     "iopub.status.idle": "2025-06-20T10:20:58.130991Z",
     "shell.execute_reply": "2025-06-20T10:20:58.130607Z",
     "shell.execute_reply.started": "2025-06-20T10:20:00.560858Z"
    },
    "papermill": {
     "duration": 0.027659,
     "end_time": "2025-06-20T10:20:58.131108",
     "exception": false,
     "start_time": "2025-06-20T10:20:58.103449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(730, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "      <th>PV</th>\n",
       "      <th>UV</th>\n",
       "      <th>Events</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-01</th>\n",
       "      <td>22711525</td>\n",
       "      <td>397349</td>\n",
       "      <td>4421.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-02</th>\n",
       "      <td>36779</td>\n",
       "      <td>3969</td>\n",
       "      <td>2289.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-03</th>\n",
       "      <td>13943875</td>\n",
       "      <td>373890</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Sales      PV      UV  Events\n",
       "Date                                        \n",
       "2022-01-01  22711525  397349  4421.0       1\n",
       "2022-01-02     36779    3969  2289.0       0\n",
       "2022-01-03  13943875  373890     NaN       1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e717d516",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T10:20:58.155691Z",
     "iopub.status.busy": "2025-06-20T10:20:58.154906Z",
     "iopub.status.idle": "2025-06-20T10:20:58.158570Z",
     "shell.execute_reply": "2025-06-20T10:20:58.158120Z",
     "shell.execute_reply.started": "2025-06-20T10:20:00.581262Z"
    },
    "papermill": {
     "duration": 0.019652,
     "end_time": "2025-06-20T10:20:58.158687",
     "exception": false,
     "start_time": "2025-06-20T10:20:58.139035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "      <th>PV</th>\n",
       "      <th>UV</th>\n",
       "      <th>Events</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-12-29</th>\n",
       "      <td>1164008</td>\n",
       "      <td>14309</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-30</th>\n",
       "      <td>3977696</td>\n",
       "      <td>60935</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31</th>\n",
       "      <td>3719764</td>\n",
       "      <td>60963</td>\n",
       "      <td>1507.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Sales     PV      UV  Events\n",
       "Date                                      \n",
       "2023-12-29  1164008  14309   193.0       0\n",
       "2023-12-30  3977696  60935     NaN       0\n",
       "2023-12-31  3719764  60963  1507.0       0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc02fec",
   "metadata": {
    "papermill": {
     "duration": 0.00777,
     "end_time": "2025-06-20T10:20:58.174600",
     "exception": false,
     "start_time": "2025-06-20T10:20:58.166830",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 단위 \n",
    "- 주 단위 W\n",
    "- 2주 단위 2W\n",
    "- 월 단위 M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f7aeb82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T10:20:58.196225Z",
     "iopub.status.busy": "2025-06-20T10:20:58.195492Z",
     "iopub.status.idle": "2025-06-20T10:20:58.198600Z",
     "shell.execute_reply": "2025-06-20T10:20:58.198984Z",
     "shell.execute_reply.started": "2025-06-20T10:20:00.606062Z"
    },
    "papermill": {
     "duration": 0.016591,
     "end_time": "2025-06-20T10:20:58.199127",
     "exception": false,
     "start_time": "2025-06-20T10:20:58.182536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Events', 'PV', 'Sales', 'T', 'UV', '_AXIS_LEN', '_AXIS_ORDERS', '_AXIS_REVERSED', '_AXIS_TO_AXIS_NUMBER', '_HANDLED_TYPES', '__abs__', '__add__', '__and__', '__annotations__', '__array__', '__array_priority__', '__array_ufunc__', '__array_wrap__', '__bool__', '__class__', '__contains__', '__copy__', '__deepcopy__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__divmod__', '__doc__', '__eq__', '__finalize__', '__floordiv__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__iadd__', '__iand__', '__ifloordiv__', '__imod__', '__imul__', '__init__', '__init_subclass__', '__invert__', '__ior__', '__ipow__', '__isub__', '__iter__', '__itruediv__', '__ixor__', '__le__', '__len__', '__lt__', '__matmul__', '__mod__', '__module__', '__mul__', '__ne__', '__neg__', '__new__', '__nonzero__', '__or__', '__pos__', '__pow__', '__radd__', '__rand__', '__rdivmod__', '__reduce__', '__reduce_ex__', '__repr__', '__rfloordiv__', '__rmatmul__', '__rmod__', '__rmul__', '__ror__', '__round__', '__rpow__', '__rsub__', '__rtruediv__', '__rxor__', '__setattr__', '__setitem__', '__setstate__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__truediv__', '__weakref__', '__xor__', '_accessors', '_accum_func', '_add_numeric_operations', '_agg_by_level', '_agg_examples_doc', '_agg_summary_and_see_also_doc', '_align_frame', '_align_series', '_arith_method', '_as_manager', '_attrs', '_box_col_values', '_can_fast_transpose', '_check_inplace_and_allows_duplicate_labels', '_check_inplace_setting', '_check_is_chained_assignment_possible', '_check_label_or_level_ambiguity', '_check_setitem_copy', '_clear_item_cache', '_clip_with_one_bound', '_clip_with_scalar', '_cmp_method', '_combine_frame', '_consolidate', '_consolidate_inplace', '_construct_axes_dict', '_construct_axes_from_arguments', '_construct_result', '_constructor', '_constructor_sliced', '_convert', '_count_level', '_data', '_dir_additions', '_dir_deletions', '_dispatch_frame_op', '_drop_axis', '_drop_labels_or_levels', '_ensure_valid_index', '_find_valid_index', '_flags', '_from_arrays', '_from_mgr', '_get_agg_axis', '_get_axis', '_get_axis_name', '_get_axis_number', '_get_axis_resolvers', '_get_block_manager_axis', '_get_bool_data', '_get_cleaned_column_resolvers', '_get_column_array', '_get_index_resolvers', '_get_item_cache', '_get_label_or_level_values', '_get_numeric_data', '_get_value', '_getitem_bool_array', '_getitem_multilevel', '_gotitem', '_hidden_attrs', '_indexed_same', '_info_axis', '_info_axis_name', '_info_axis_number', '_info_repr', '_init_mgr', '_inplace_method', '_internal_names', '_internal_names_set', '_is_copy', '_is_homogeneous_type', '_is_label_or_level_reference', '_is_label_reference', '_is_level_reference', '_is_mixed_type', '_is_view', '_iset_item', '_iset_item_mgr', '_iset_not_inplace', '_item_cache', '_iter_column_arrays', '_ixs', '_join_compat', '_logical_func', '_logical_method', '_maybe_cache_changed', '_maybe_update_cacher', '_metadata', '_mgr', '_min_count_stat_function', '_needs_reindex_multi', '_protect_consolidate', '_reduce', '_reindex_axes', '_reindex_columns', '_reindex_index', '_reindex_multi', '_reindex_with_indexers', '_replace_columnwise', '_repr_data_resource_', '_repr_fits_horizontal_', '_repr_fits_vertical_', '_repr_html_', '_repr_latex_', '_reset_cache', '_reset_cacher', '_sanitize_column', '_series', '_set_axis', '_set_axis_name', '_set_axis_nocheck', '_set_is_copy', '_set_item', '_set_item_frame_value', '_set_item_mgr', '_set_value', '_setitem_array', '_setitem_frame', '_setitem_slice', '_slice', '_stat_axis', '_stat_axis_name', '_stat_axis_number', '_stat_function', '_stat_function_ddof', '_take_with_is_copy', '_to_dict_of_blocks', '_typ', '_update_inplace', '_validate_dtype', '_values', '_where', 'abs', 'add', 'add_prefix', 'add_suffix', 'agg', 'aggregate', 'align', 'all', 'any', 'append', 'apply', 'applymap', 'asfreq', 'asof', 'assign', 'astype', 'at', 'at_time', 'attrs', 'axes', 'backfill', 'between_time', 'bfill', 'bool', 'boxplot', 'clip', 'columns', 'combine', 'combine_first', 'compare', 'convert_dtypes', 'copy', 'corr', 'corrwith', 'count', 'cov', 'cummax', 'cummin', 'cumprod', 'cumsum', 'describe', 'diff', 'div', 'divide', 'dot', 'drop', 'drop_duplicates', 'droplevel', 'dropna', 'dtypes', 'duplicated', 'empty', 'eq', 'equals', 'eval', 'ewm', 'expanding', 'explode', 'ffill', 'fillna', 'filter', 'first', 'first_valid_index', 'flags', 'floordiv', 'from_dict', 'from_records', 'ge', 'get', 'groupby', 'gt', 'head', 'hist', 'iat', 'idxmax', 'idxmin', 'iloc', 'index', 'infer_objects', 'info', 'insert', 'interpolate', 'isin', 'isna', 'isnull', 'items', 'iteritems', 'iterrows', 'itertuples', 'join', 'keys', 'kurt', 'kurtosis', 'last', 'last_valid_index', 'le', 'loc', 'lookup', 'lt', 'mad', 'mask', 'max', 'mean', 'median', 'melt', 'memory_usage', 'merge', 'min', 'mod', 'mode', 'mul', 'multiply', 'ndim', 'ne', 'nlargest', 'notna', 'notnull', 'nsmallest', 'nunique', 'pad', 'pct_change', 'pipe', 'pivot', 'pivot_table', 'plot', 'pop', 'pow', 'prod', 'product', 'quantile', 'query', 'radd', 'rank', 'rdiv', 'reindex', 'reindex_like', 'rename', 'rename_axis', 'reorder_levels', 'replace', 'resample', 'reset_index', 'rfloordiv', 'rmod', 'rmul', 'rolling', 'round', 'rpow', 'rsub', 'rtruediv', 'sample', 'select_dtypes', 'sem', 'set_axis', 'set_flags', 'set_index', 'shape', 'shift', 'size', 'skew', 'slice_shift', 'sort_index', 'sort_values', 'squeeze', 'stack', 'std', 'style', 'sub', 'subtract', 'sum', 'swapaxes', 'swaplevel', 'tail', 'take', 'to_clipboard', 'to_csv', 'to_dict', 'to_excel', 'to_feather', 'to_gbq', 'to_hdf', 'to_html', 'to_json', 'to_latex', 'to_markdown', 'to_numpy', 'to_parquet', 'to_period', 'to_pickle', 'to_records', 'to_sql', 'to_stata', 'to_string', 'to_timestamp', 'to_xarray', 'to_xml', 'transform', 'transpose', 'truediv', 'truncate', 'tz_convert', 'tz_localize', 'unstack', 'update', 'value_counts', 'values', 'var', 'where', 'xs']\n"
     ]
    }
   ],
   "source": [
    "print(dir(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5e31bae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T10:20:58.225980Z",
     "iopub.status.busy": "2025-06-20T10:20:58.224929Z",
     "iopub.status.idle": "2025-06-20T10:20:58.230342Z",
     "shell.execute_reply": "2025-06-20T10:20:58.229356Z",
     "shell.execute_reply.started": "2025-06-20T10:20:00.619249Z"
    },
    "papermill": {
     "duration": 0.022945,
     "end_time": "2025-06-20T10:20:58.230552",
     "exception": false,
     "start_time": "2025-06-20T10:20:58.207607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method resample in module pandas.core.frame:\n",
      "\n",
      "resample(rule, axis=0, closed: 'str | None' = None, label: 'str | None' = None, convention: 'str' = 'start', kind: 'str | None' = None, loffset=None, base: 'int | None' = None, on=None, level=None, origin: 'str | TimestampConvertibleTypes' = 'start_day', offset: 'TimedeltaConvertibleTypes | None' = None) -> 'Resampler' method of pandas.core.frame.DataFrame instance\n",
      "    Resample time-series data.\n",
      "    \n",
      "    Convenience method for frequency conversion and resampling of time series.\n",
      "    The object must have a datetime-like index (`DatetimeIndex`, `PeriodIndex`,\n",
      "    or `TimedeltaIndex`), or the caller must pass the label of a datetime-like\n",
      "    series/index to the ``on``/``level`` keyword parameter.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    rule : DateOffset, Timedelta or str\n",
      "        The offset string or object representing target conversion.\n",
      "    axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "        Which axis to use for up- or down-sampling. For `Series` this\n",
      "        will default to 0, i.e. along the rows. Must be\n",
      "        `DatetimeIndex`, `TimedeltaIndex` or `PeriodIndex`.\n",
      "    closed : {'right', 'left'}, default None\n",
      "        Which side of bin interval is closed. The default is 'left'\n",
      "        for all frequency offsets except for 'M', 'A', 'Q', 'BM',\n",
      "        'BA', 'BQ', and 'W' which all have a default of 'right'.\n",
      "    label : {'right', 'left'}, default None\n",
      "        Which bin edge label to label bucket with. The default is 'left'\n",
      "        for all frequency offsets except for 'M', 'A', 'Q', 'BM',\n",
      "        'BA', 'BQ', and 'W' which all have a default of 'right'.\n",
      "    convention : {'start', 'end', 's', 'e'}, default 'start'\n",
      "        For `PeriodIndex` only, controls whether to use the start or\n",
      "        end of `rule`.\n",
      "    kind : {'timestamp', 'period'}, optional, default None\n",
      "        Pass 'timestamp' to convert the resulting index to a\n",
      "        `DateTimeIndex` or 'period' to convert it to a `PeriodIndex`.\n",
      "        By default the input representation is retained.\n",
      "    loffset : timedelta, default None\n",
      "        Adjust the resampled time labels.\n",
      "    \n",
      "        .. deprecated:: 1.1.0\n",
      "            You should add the loffset to the `df.index` after the resample.\n",
      "            See below.\n",
      "    \n",
      "    base : int, default 0\n",
      "        For frequencies that evenly subdivide 1 day, the \"origin\" of the\n",
      "        aggregated intervals. For example, for '5min' frequency, base could\n",
      "        range from 0 through 4. Defaults to 0.\n",
      "    \n",
      "        .. deprecated:: 1.1.0\n",
      "            The new arguments that you should use are 'offset' or 'origin'.\n",
      "    \n",
      "    on : str, optional\n",
      "        For a DataFrame, column to use instead of index for resampling.\n",
      "        Column must be datetime-like.\n",
      "    level : str or int, optional\n",
      "        For a MultiIndex, level (name or number) to use for\n",
      "        resampling. `level` must be datetime-like.\n",
      "    origin : {'epoch', 'start', 'start_day', 'end', 'end_day'}, Timestamp\n",
      "        or str, default 'start_day'\n",
      "        The timestamp on which to adjust the grouping. The timezone of origin\n",
      "        must match the timezone of the index.\n",
      "        If a timestamp is not used, these values are also supported:\n",
      "    \n",
      "        - 'epoch': `origin` is 1970-01-01\n",
      "        - 'start': `origin` is the first value of the timeseries\n",
      "        - 'start_day': `origin` is the first day at midnight of the timeseries\n",
      "    \n",
      "        .. versionadded:: 1.1.0\n",
      "    \n",
      "        - 'end': `origin` is the last value of the timeseries\n",
      "        - 'end_day': `origin` is the ceiling midnight of the last day\n",
      "    \n",
      "        .. versionadded:: 1.3.0\n",
      "    \n",
      "    offset : Timedelta or str, default is None\n",
      "        An offset timedelta added to the origin.\n",
      "    \n",
      "        .. versionadded:: 1.1.0\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    pandas.core.Resampler\n",
      "        :class:`~pandas.core.Resampler` object.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    Series.resample : Resample a Series.\n",
      "    DataFrame.resample : Resample a DataFrame.\n",
      "    groupby : Group DataFrame by mapping, function, label, or list of labels.\n",
      "    asfreq : Reindex a DataFrame with the given frequency without grouping.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    See the `user guide\n",
      "    <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#resampling>`__\n",
      "    for more.\n",
      "    \n",
      "    To learn more about the offset strings, please see `this link\n",
      "    <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#dateoffset-objects>`__.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    Start by creating a series with 9 one minute timestamps.\n",
      "    \n",
      "    >>> index = pd.date_range('1/1/2000', periods=9, freq='T')\n",
      "    >>> series = pd.Series(range(9), index=index)\n",
      "    >>> series\n",
      "    2000-01-01 00:00:00    0\n",
      "    2000-01-01 00:01:00    1\n",
      "    2000-01-01 00:02:00    2\n",
      "    2000-01-01 00:03:00    3\n",
      "    2000-01-01 00:04:00    4\n",
      "    2000-01-01 00:05:00    5\n",
      "    2000-01-01 00:06:00    6\n",
      "    2000-01-01 00:07:00    7\n",
      "    2000-01-01 00:08:00    8\n",
      "    Freq: T, dtype: int64\n",
      "    \n",
      "    Downsample the series into 3 minute bins and sum the values\n",
      "    of the timestamps falling into a bin.\n",
      "    \n",
      "    >>> series.resample('3T').sum()\n",
      "    2000-01-01 00:00:00     3\n",
      "    2000-01-01 00:03:00    12\n",
      "    2000-01-01 00:06:00    21\n",
      "    Freq: 3T, dtype: int64\n",
      "    \n",
      "    Downsample the series into 3 minute bins as above, but label each\n",
      "    bin using the right edge instead of the left. Please note that the\n",
      "    value in the bucket used as the label is not included in the bucket,\n",
      "    which it labels. For example, in the original series the\n",
      "    bucket ``2000-01-01 00:03:00`` contains the value 3, but the summed\n",
      "    value in the resampled bucket with the label ``2000-01-01 00:03:00``\n",
      "    does not include 3 (if it did, the summed value would be 6, not 3).\n",
      "    To include this value close the right side of the bin interval as\n",
      "    illustrated in the example below this one.\n",
      "    \n",
      "    >>> series.resample('3T', label='right').sum()\n",
      "    2000-01-01 00:03:00     3\n",
      "    2000-01-01 00:06:00    12\n",
      "    2000-01-01 00:09:00    21\n",
      "    Freq: 3T, dtype: int64\n",
      "    \n",
      "    Downsample the series into 3 minute bins as above, but close the right\n",
      "    side of the bin interval.\n",
      "    \n",
      "    >>> series.resample('3T', label='right', closed='right').sum()\n",
      "    2000-01-01 00:00:00     0\n",
      "    2000-01-01 00:03:00     6\n",
      "    2000-01-01 00:06:00    15\n",
      "    2000-01-01 00:09:00    15\n",
      "    Freq: 3T, dtype: int64\n",
      "    \n",
      "    Upsample the series into 30 second bins.\n",
      "    \n",
      "    >>> series.resample('30S').asfreq()[0:5]   # Select first 5 rows\n",
      "    2000-01-01 00:00:00   0.0\n",
      "    2000-01-01 00:00:30   NaN\n",
      "    2000-01-01 00:01:00   1.0\n",
      "    2000-01-01 00:01:30   NaN\n",
      "    2000-01-01 00:02:00   2.0\n",
      "    Freq: 30S, dtype: float64\n",
      "    \n",
      "    Upsample the series into 30 second bins and fill the ``NaN``\n",
      "    values using the ``pad`` method.\n",
      "    \n",
      "    >>> series.resample('30S').pad()[0:5]\n",
      "    2000-01-01 00:00:00    0\n",
      "    2000-01-01 00:00:30    0\n",
      "    2000-01-01 00:01:00    1\n",
      "    2000-01-01 00:01:30    1\n",
      "    2000-01-01 00:02:00    2\n",
      "    Freq: 30S, dtype: int64\n",
      "    \n",
      "    Upsample the series into 30 second bins and fill the\n",
      "    ``NaN`` values using the ``bfill`` method.\n",
      "    \n",
      "    >>> series.resample('30S').bfill()[0:5]\n",
      "    2000-01-01 00:00:00    0\n",
      "    2000-01-01 00:00:30    1\n",
      "    2000-01-01 00:01:00    1\n",
      "    2000-01-01 00:01:30    2\n",
      "    2000-01-01 00:02:00    2\n",
      "    Freq: 30S, dtype: int64\n",
      "    \n",
      "    Pass a custom function via ``apply``\n",
      "    \n",
      "    >>> def custom_resampler(arraylike):\n",
      "    ...     return np.sum(arraylike) + 5\n",
      "    ...\n",
      "    >>> series.resample('3T').apply(custom_resampler)\n",
      "    2000-01-01 00:00:00     8\n",
      "    2000-01-01 00:03:00    17\n",
      "    2000-01-01 00:06:00    26\n",
      "    Freq: 3T, dtype: int64\n",
      "    \n",
      "    For a Series with a PeriodIndex, the keyword `convention` can be\n",
      "    used to control whether to use the start or end of `rule`.\n",
      "    \n",
      "    Resample a year by quarter using 'start' `convention`. Values are\n",
      "    assigned to the first quarter of the period.\n",
      "    \n",
      "    >>> s = pd.Series([1, 2], index=pd.period_range('2012-01-01',\n",
      "    ...                                             freq='A',\n",
      "    ...                                             periods=2))\n",
      "    >>> s\n",
      "    2012    1\n",
      "    2013    2\n",
      "    Freq: A-DEC, dtype: int64\n",
      "    >>> s.resample('Q', convention='start').asfreq()\n",
      "    2012Q1    1.0\n",
      "    2012Q2    NaN\n",
      "    2012Q3    NaN\n",
      "    2012Q4    NaN\n",
      "    2013Q1    2.0\n",
      "    2013Q2    NaN\n",
      "    2013Q3    NaN\n",
      "    2013Q4    NaN\n",
      "    Freq: Q-DEC, dtype: float64\n",
      "    \n",
      "    Resample quarters by month using 'end' `convention`. Values are\n",
      "    assigned to the last month of the period.\n",
      "    \n",
      "    >>> q = pd.Series([1, 2, 3, 4], index=pd.period_range('2018-01-01',\n",
      "    ...                                                   freq='Q',\n",
      "    ...                                                   periods=4))\n",
      "    >>> q\n",
      "    2018Q1    1\n",
      "    2018Q2    2\n",
      "    2018Q3    3\n",
      "    2018Q4    4\n",
      "    Freq: Q-DEC, dtype: int64\n",
      "    >>> q.resample('M', convention='end').asfreq()\n",
      "    2018-03    1.0\n",
      "    2018-04    NaN\n",
      "    2018-05    NaN\n",
      "    2018-06    2.0\n",
      "    2018-07    NaN\n",
      "    2018-08    NaN\n",
      "    2018-09    3.0\n",
      "    2018-10    NaN\n",
      "    2018-11    NaN\n",
      "    2018-12    4.0\n",
      "    Freq: M, dtype: float64\n",
      "    \n",
      "    For DataFrame objects, the keyword `on` can be used to specify the\n",
      "    column instead of the index for resampling.\n",
      "    \n",
      "    >>> d = {'price': [10, 11, 9, 13, 14, 18, 17, 19],\n",
      "    ...      'volume': [50, 60, 40, 100, 50, 100, 40, 50]}\n",
      "    >>> df = pd.DataFrame(d)\n",
      "    >>> df['week_starting'] = pd.date_range('01/01/2018',\n",
      "    ...                                     periods=8,\n",
      "    ...                                     freq='W')\n",
      "    >>> df\n",
      "       price  volume week_starting\n",
      "    0     10      50    2018-01-07\n",
      "    1     11      60    2018-01-14\n",
      "    2      9      40    2018-01-21\n",
      "    3     13     100    2018-01-28\n",
      "    4     14      50    2018-02-04\n",
      "    5     18     100    2018-02-11\n",
      "    6     17      40    2018-02-18\n",
      "    7     19      50    2018-02-25\n",
      "    >>> df.resample('M', on='week_starting').mean()\n",
      "                   price  volume\n",
      "    week_starting\n",
      "    2018-01-31     10.75    62.5\n",
      "    2018-02-28     17.00    60.0\n",
      "    \n",
      "    For a DataFrame with MultiIndex, the keyword `level` can be used to\n",
      "    specify on which level the resampling needs to take place.\n",
      "    \n",
      "    >>> days = pd.date_range('1/1/2000', periods=4, freq='D')\n",
      "    >>> d2 = {'price': [10, 11, 9, 13, 14, 18, 17, 19],\n",
      "    ...       'volume': [50, 60, 40, 100, 50, 100, 40, 50]}\n",
      "    >>> df2 = pd.DataFrame(\n",
      "    ...     d2,\n",
      "    ...     index=pd.MultiIndex.from_product(\n",
      "    ...         [days, ['morning', 'afternoon']]\n",
      "    ...     )\n",
      "    ... )\n",
      "    >>> df2\n",
      "                          price  volume\n",
      "    2000-01-01 morning       10      50\n",
      "               afternoon     11      60\n",
      "    2000-01-02 morning        9      40\n",
      "               afternoon     13     100\n",
      "    2000-01-03 morning       14      50\n",
      "               afternoon     18     100\n",
      "    2000-01-04 morning       17      40\n",
      "               afternoon     19      50\n",
      "    >>> df2.resample('D', level=0).sum()\n",
      "                price  volume\n",
      "    2000-01-01     21     110\n",
      "    2000-01-02     22     140\n",
      "    2000-01-03     32     150\n",
      "    2000-01-04     36      90\n",
      "    \n",
      "    If you want to adjust the start of the bins based on a fixed timestamp:\n",
      "    \n",
      "    >>> start, end = '2000-10-01 23:30:00', '2000-10-02 00:30:00'\n",
      "    >>> rng = pd.date_range(start, end, freq='7min')\n",
      "    >>> ts = pd.Series(np.arange(len(rng)) * 3, index=rng)\n",
      "    >>> ts\n",
      "    2000-10-01 23:30:00     0\n",
      "    2000-10-01 23:37:00     3\n",
      "    2000-10-01 23:44:00     6\n",
      "    2000-10-01 23:51:00     9\n",
      "    2000-10-01 23:58:00    12\n",
      "    2000-10-02 00:05:00    15\n",
      "    2000-10-02 00:12:00    18\n",
      "    2000-10-02 00:19:00    21\n",
      "    2000-10-02 00:26:00    24\n",
      "    Freq: 7T, dtype: int64\n",
      "    \n",
      "    >>> ts.resample('17min').sum()\n",
      "    2000-10-01 23:14:00     0\n",
      "    2000-10-01 23:31:00     9\n",
      "    2000-10-01 23:48:00    21\n",
      "    2000-10-02 00:05:00    54\n",
      "    2000-10-02 00:22:00    24\n",
      "    Freq: 17T, dtype: int64\n",
      "    \n",
      "    >>> ts.resample('17min', origin='epoch').sum()\n",
      "    2000-10-01 23:18:00     0\n",
      "    2000-10-01 23:35:00    18\n",
      "    2000-10-01 23:52:00    27\n",
      "    2000-10-02 00:09:00    39\n",
      "    2000-10-02 00:26:00    24\n",
      "    Freq: 17T, dtype: int64\n",
      "    \n",
      "    >>> ts.resample('17min', origin='2000-01-01').sum()\n",
      "    2000-10-01 23:24:00     3\n",
      "    2000-10-01 23:41:00    15\n",
      "    2000-10-01 23:58:00    45\n",
      "    2000-10-02 00:15:00    45\n",
      "    Freq: 17T, dtype: int64\n",
      "    \n",
      "    If you want to adjust the start of the bins with an `offset` Timedelta, the two\n",
      "    following lines are equivalent:\n",
      "    \n",
      "    >>> ts.resample('17min', origin='start').sum()\n",
      "    2000-10-01 23:30:00     9\n",
      "    2000-10-01 23:47:00    21\n",
      "    2000-10-02 00:04:00    54\n",
      "    2000-10-02 00:21:00    24\n",
      "    Freq: 17T, dtype: int64\n",
      "    \n",
      "    >>> ts.resample('17min', offset='23h30min').sum()\n",
      "    2000-10-01 23:30:00     9\n",
      "    2000-10-01 23:47:00    21\n",
      "    2000-10-02 00:04:00    54\n",
      "    2000-10-02 00:21:00    24\n",
      "    Freq: 17T, dtype: int64\n",
      "    \n",
      "    If you want to take the largest Timestamp as the end of the bins:\n",
      "    \n",
      "    >>> ts.resample('17min', origin='end').sum()\n",
      "    2000-10-01 23:35:00     0\n",
      "    2000-10-01 23:52:00    18\n",
      "    2000-10-02 00:09:00    27\n",
      "    2000-10-02 00:26:00    63\n",
      "    Freq: 17T, dtype: int64\n",
      "    \n",
      "    In contrast with the `start_day`, you can use `end_day` to take the ceiling\n",
      "    midnight of the largest Timestamp as the end of the bins and drop the bins\n",
      "    not containing data:\n",
      "    \n",
      "    >>> ts.resample('17min', origin='end_day').sum()\n",
      "    2000-10-01 23:38:00     3\n",
      "    2000-10-01 23:55:00    15\n",
      "    2000-10-02 00:12:00    45\n",
      "    2000-10-02 00:29:00    45\n",
      "    Freq: 17T, dtype: int64\n",
      "    \n",
      "    To replace the use of the deprecated `base` argument, you can now use `offset`,\n",
      "    in this example it is equivalent to have `base=2`:\n",
      "    \n",
      "    >>> ts.resample('17min', offset='2min').sum()\n",
      "    2000-10-01 23:16:00     0\n",
      "    2000-10-01 23:33:00     9\n",
      "    2000-10-01 23:50:00    36\n",
      "    2000-10-02 00:07:00    39\n",
      "    2000-10-02 00:24:00    24\n",
      "    Freq: 17T, dtype: int64\n",
      "    \n",
      "    To replace the use of the deprecated `loffset` argument:\n",
      "    \n",
      "    >>> from pandas.tseries.frequencies import to_offset\n",
      "    >>> loffset = '19min'\n",
      "    >>> ts_out = ts.resample('17min').sum()\n",
      "    >>> ts_out.index = ts_out.index + to_offset(loffset)\n",
      "    >>> ts_out\n",
      "    2000-10-01 23:33:00     0\n",
      "    2000-10-01 23:50:00     9\n",
      "    2000-10-02 00:07:00    21\n",
      "    2000-10-02 00:24:00    54\n",
      "    2000-10-02 00:41:00    24\n",
      "    Freq: 17T, dtype: int64\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(help(df.resample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5929a813",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T10:20:58.263670Z",
     "iopub.status.busy": "2025-06-20T10:20:58.262729Z",
     "iopub.status.idle": "2025-06-20T10:20:58.288924Z",
     "shell.execute_reply": "2025-06-20T10:20:58.288466Z",
     "shell.execute_reply.started": "2025-06-20T10:20:00.637569Z"
    },
    "papermill": {
     "duration": 0.043281,
     "end_time": "2025-06-20T10:20:58.289039",
     "exception": false,
     "start_time": "2025-06-20T10:20:58.245758",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "      <th>PV</th>\n",
       "      <th>UV</th>\n",
       "      <th>Events</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-02</th>\n",
       "      <td>22748304</td>\n",
       "      <td>401318</td>\n",
       "      <td>6710.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-09</th>\n",
       "      <td>33373822</td>\n",
       "      <td>1148464</td>\n",
       "      <td>15189.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-16</th>\n",
       "      <td>20754519</td>\n",
       "      <td>283773</td>\n",
       "      <td>9344.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-23</th>\n",
       "      <td>21880751</td>\n",
       "      <td>538633</td>\n",
       "      <td>9841.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-30</th>\n",
       "      <td>28878452</td>\n",
       "      <td>560814</td>\n",
       "      <td>7808.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Sales       PV       UV  Events\n",
       "Date                                          \n",
       "2022-01-02  22748304   401318   6710.0       1\n",
       "2022-01-09  33373822  1148464  15189.0       2\n",
       "2022-01-16  20754519   283773   9344.0       0\n",
       "2022-01-23  21880751   538633   9841.0       1\n",
       "2022-01-30  28878452   560814   7808.0       1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_w = df.resample('W').sum()\n",
    "df_w.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ff04b2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T10:20:58.314383Z",
     "iopub.status.busy": "2025-06-20T10:20:58.313651Z",
     "iopub.status.idle": "2025-06-20T10:20:58.317456Z",
     "shell.execute_reply": "2025-06-20T10:20:58.316863Z",
     "shell.execute_reply.started": "2025-06-20T10:20:00.664513Z"
    },
    "papermill": {
     "duration": 0.018923,
     "end_time": "2025-06-20T10:20:58.317576",
     "exception": false,
     "start_time": "2025-06-20T10:20:58.298653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99165648"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ma = df_w['Sales'].max()\n",
    "ma # 99165648"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "197dbf39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T10:20:58.353552Z",
     "iopub.status.busy": "2025-06-20T10:20:58.352348Z",
     "iopub.status.idle": "2025-06-20T10:20:58.356489Z",
     "shell.execute_reply": "2025-06-20T10:20:58.357261Z",
     "shell.execute_reply.started": "2025-06-20T10:20:00.672209Z"
    },
    "papermill": {
     "duration": 0.027446,
     "end_time": "2025-06-20T10:20:58.357528",
     "exception": false,
     "start_time": "2025-06-20T10:20:58.330082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7526598"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi = df_w['Sales'].min()\n",
    "mi # 7526598"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4fab4dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T10:20:58.395157Z",
     "iopub.status.busy": "2025-06-20T10:20:58.394450Z",
     "iopub.status.idle": "2025-06-20T10:20:58.398568Z",
     "shell.execute_reply": "2025-06-20T10:20:58.397750Z",
     "shell.execute_reply.started": "2025-06-20T10:20:00.686940Z"
    },
    "papermill": {
     "duration": 0.023012,
     "end_time": "2025-06-20T10:20:58.398771",
     "exception": false,
     "start_time": "2025-06-20T10:20:58.375759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91639050\n"
     ]
    }
   ],
   "source": [
    "print(abs(ma - mi)) # 91639050"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1633303,
     "sourceId": 12211878,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30145,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8.416609,
   "end_time": "2025-06-20T10:20:58.925114",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-20T10:20:50.508505",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
